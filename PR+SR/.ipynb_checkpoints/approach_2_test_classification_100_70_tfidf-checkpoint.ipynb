{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SY5pZ5rLXlyS"
   },
   "source": [
    "**Importing pandas here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KKrMV7EtNjXc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLzXltu1XuA7"
   },
   "source": [
    "**Importing dataset and Having a look at dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "BNRbAmEQNuh9",
    "outputId": "5a4053d1-8125-47e1-ea17-9b860e42c922"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>کہ کے لے لی شام دلے کی</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>اب اگر اس نے کچھ جواب دیا تو اس کی گانڈ مار دی...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>اب ان چوتیوں نے وہ جو کنسرٹ ہو رہا تھا وہ بھی ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>اب ان کی گانڈ میں ہاتھ ڈال کر انتڑیاں نکالے گا...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>اب تک سکی سب سے اچھی ویڈیو ہے</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  target\n",
       "0                             کہ کے لے لی شام دلے کی       1\n",
       "1  اب اگر اس نے کچھ جواب دیا تو اس کی گانڈ مار دی...       1\n",
       "2  اب ان چوتیوں نے وہ جو کنسرٹ ہو رہا تھا وہ بھی ...       1\n",
       "3  اب ان کی گانڈ میں ہاتھ ڈال کر انتڑیاں نکالے گا...       1\n",
       "4                      اب تک سکی سب سے اچھی ویڈیو ہے       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"Dataset 1.csv\")\n",
    "test=pd.read_csv(\"Dataset 2.csv\")\n",
    "stopw=pd.read_csv(\"Stopword.csv\")\n",
    "test=test[['tweet','target']]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYHGQGOlX4vD"
   },
   "source": [
    "### Dataset Cleaning process\n",
    "1. Remove Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdiOuDZ2N_SN",
    "outputId": "f29071b5-d82c-4e7c-d537-83583b424b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1213\n",
      "1    1187\n",
      "Name: target, dtype: int64\n",
      "1    1108\n",
      "0    1062\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "train.replace(\"\", nan_value, inplace=True)\n",
    "train.dropna(subset = [\"tweet\"], inplace=True)\n",
    "train.tail()\n",
    "print(train['target'].value_counts())\n",
    "nan_value = float(\"NaN\")\n",
    "test.replace(\"\", nan_value, inplace=True)\n",
    "test.dropna(subset = [\"tweet\"], inplace=True)\n",
    "test.tail()\n",
    "print(test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIHQXJa9YHht"
   },
   "source": [
    "### Dataset Cleaning process\n",
    "2. Acquring Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E-PhNvnbN_9X"
   },
   "outputs": [],
   "source": [
    "stopwords=[]\n",
    "for i in (stopw['Stopwords']):\n",
    "    stopwords.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icHw-ILnYQfr"
   },
   "source": [
    "### Dataset Cleaning process\n",
    "1. Remove Missing values\n",
    "2. Tokenization\n",
    "3. Cleaning Extra Characters\n",
    "4. Removal of Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0dcrZRyOOlx"
   },
   "outputs": [],
   "source": [
    "from urduhack.preprocessing import remove_punctuation\n",
    "tain_corpus=[]\n",
    "for i in (train['tweet']):\n",
    "        i=remove_punctuation(i)\n",
    "        review=i.split()\n",
    "        review=[word for word in review if word not in stopwords]\n",
    "        review=' '.join(review)\n",
    "        tain_corpus.append(review)\n",
    "test_corpus=[]\n",
    "for i in (test['tweet']):\n",
    "        i=remove_punctuation(i)\n",
    "        review=i.split()\n",
    "        review=[word for word in review if word not in stopwords]\n",
    "        review=' '.join(review)\n",
    "        test_corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e66VhtyrYbeB"
   },
   "source": [
    "### Feature Extraction\n",
    "1. **TFIDF** Term Frequency Inverse Document Frequencey\n",
    "2. Looking at vocubalary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "naeZEYaROW73",
    "outputId": "5184b293-0bf2-484f-bb6c-2b8538c7a0bc"
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer    \n",
    "# cv=CountVectorizer(max_features=3000)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "max_feature_num = 10000\n",
    "train_vectorizer = TfidfVectorizer(max_features=max_feature_num)\n",
    "X_train=train_vectorizer.fit_transform(tain_corpus).toarray()\n",
    "y_train=train['target']\n",
    "train_vectorizer.vocabulary_\n",
    "test_vectorizer = TfidfVectorizer(max_features=max_feature_num,vocabulary=train_vectorizer.vocabulary_)\n",
    "X_test=test_vectorizer.fit_transform(test_corpus).toarray()\n",
    "y_test=test['target']\n",
    "train_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWOqT8vhYzRj"
   },
   "source": [
    "## Test Train Split\n",
    "1. 75% Training 25% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOf4JGDVObkT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test1,y_train,y_test1 = train_test_split(X_train, y_train, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiDEZf5kZFd6"
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfG-q9HyOh8k"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier=DecisionTreeClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "pred=classifier.predict(X_test)\n",
    "dtc_probs = classifier.predict_proba(X_test)\n",
    "dtc_probs=dtc_probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dsm7kyDZMWN"
   },
   "source": [
    "# Decision Tree Evaluation\n",
    "1. Test Train split Accuracy, precision, recall and f1 score\n",
    "2. F1 Score for 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjtfJGPMOnTK",
    "outputId": "03b0699c-e237-4e67-efbe-434126150baa"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,pred)\n",
    "print(\"----------------Test Train Score Complete Datasets---------------\")\n",
    "print(\"confusion matrix\")\n",
    "print(cm)\n",
    "acc=accuracy_score(y_test, pred)\n",
    "pr=precision_score(y_test, pred,average='macro')\n",
    "re=recall_score(y_test, pred,average='macro')\n",
    "fs=f1_score(y_test, pred,average='macro')\n",
    "print('Accuracy score: {}'.format(acc))\n",
    "print('Precision score: {}'.format(pr))\n",
    "print('F1 score: {}'.format(fs))\n",
    "print('Recall score: {}'.format(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8YYQPJsZgOe"
   },
   "source": [
    "## AUC ROC Curve\n",
    "1. AUC Value\n",
    "2. Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "H1rDn2ipPYYy",
    "outputId": "efffa1d5-d8a2-4a08-98ea-2f7e9e62a25a"
   },
   "outputs": [],
   "source": [
    "# submission={\n",
    "#     'id':data['id'],\n",
    "#     'target':test_pred,\n",
    "#     'score':dtc_probs,\n",
    "# }\n",
    "\n",
    "# submission=pd.DataFrame(submission)\n",
    "# submission.to_csv(\"subt.csv\")\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "lr_auc = roc_auc_score(y_test, dtc_probs)\n",
    "# summarize scores\n",
    "print('Classifier: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, dtc_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, 'r',marker='.', label='Decision Tree')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "kf = KFold(n_splits=4)\n",
    "mae_train = []\n",
    "mae_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dm2NtbrZqTh"
   },
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "YLKbb-7LPcIC",
    "outputId": "19fd59c5-5b59-464e-dcef-24a8a1a616e9"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_curve():\n",
    "    # instantiate\n",
    "    lg = DecisionTreeClassifier()\n",
    "\n",
    "    # fit\n",
    "    lg.fit(X_test, y_test)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "        \n",
    "    x1 = np.linspace(0, 10, 8, endpoint=True) produces\n",
    "        8 evenly spaced points in the range 0 to 10\n",
    "    \"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(lg, X_test, y_test, n_jobs=-1, cv=10, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Decison Tree\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n",
    "plot_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0Hjl41MZx6J"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jQFugpdSv2r"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y_train)\n",
    "pred=classifier.predict(X_test)\n",
    "dtc_probs = classifier.predict_proba(X_test)\n",
    "dtc_probs=dtc_probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x39ZnV5NZ81i"
   },
   "source": [
    "## Logistic Regression\n",
    "1. Test Train split Accuracy, precision, recall and f1 score\n",
    "2. F1 Score for 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9qBudNGSxPe",
    "outputId": "bf0affb9-d790-4c33-a2ab-4bdcfe36c004"
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,pred)\n",
    "print(\"Complete Dataset Results\")\n",
    "print(\"confusion matrix\")\n",
    "print(cm)\n",
    "acc=accuracy_score(y_test, pred)\n",
    "pr=precision_score(y_test, pred,average='macro')\n",
    "re=recall_score(y_test, pred,average='macro')\n",
    "fs=f1_score(y_test, pred,average='macro')\n",
    "print('Accuracy score: {}'.format(acc))\n",
    "print('Precision score: {}'.format(pr))\n",
    "print('F1 score: {}'.format(fs))\n",
    "print('Recall score: {}'.format(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKumwyyMaDGX"
   },
   "source": [
    "#AUC ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Wu3j1_GwS_be",
    "outputId": "c766fc48-0289-44e4-d78a-a58a1ae8a19f"
   },
   "outputs": [],
   "source": [
    "# submission={\n",
    "#     'id':data['id'],\n",
    "#     'target':test_pred,\n",
    "#     'score':dtc_probs,\n",
    "# }\n",
    "\n",
    "# submission=pd.DataFrame(submission)\n",
    "# submission.to_csv(\"subt.csv\")\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "lr_auc = roc_auc_score(y_test, dtc_probs)\n",
    "# summarize scores\n",
    "print('Classifier: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, dtc_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, 'r',marker='.', label='Logistic Regression')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "kf = KFold(n_splits=4)\n",
    "mae_train = []\n",
    "mae_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BlgZ0epaH87"
   },
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "YYLzX_feTLPr",
    "outputId": "3a02e05a-903a-402b-fbc2-a43e54908d7c"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_curve():\n",
    "    # instantiate\n",
    "    lg = LogisticRegression()\n",
    "\n",
    "    # fit\n",
    "    lg.fit(X_test , y_test)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "        \n",
    "    x1 = np.linspace(0, 10, 8, endpoint=True) produces\n",
    "        8 evenly spaced points in the range 0 to 10\n",
    "    \"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(lg, X_test, y_test, n_jobs=-1, cv=10, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Logistic Regression\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n",
    "plot_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kj6xiaNvaRH-"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gcSbRxYTZpT"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier=SVC(probability=True)\n",
    "classifier.fit(X_train,y_train)\n",
    "pred=classifier.predict(X_test)\n",
    "dtc_probs = classifier.predict_proba(X_test)\n",
    "dtc_probs=dtc_probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT6sI7RIaVoV"
   },
   "source": [
    "## SVM\n",
    "1. Test Train split Accuracy, precision, recall and f1 score\n",
    "2. F1 Score for 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hm4K-ItzTlcQ",
    "outputId": "d0d13be8-76c7-4205-f864-5a8e1ab09a07"
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,pred)\n",
    "print(\"Complete Dataset Score\")\n",
    "print(\"confusion matrix\")\n",
    "print(cm)\n",
    "acc=accuracy_score(y_test, pred)\n",
    "pr=precision_score(y_test, pred,average='macro')\n",
    "re=recall_score(y_test, pred,average='macro')\n",
    "fs=f1_score(y_test, pred,average='macro')\n",
    "print('Accuracy score: {}'.format(acc))\n",
    "print('Precision score: {}'.format(pr))\n",
    "print('F1 score: {}'.format(fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjZmTNyCaacJ"
   },
   "source": [
    "## AUC ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "ucmRbaUcXkDK",
    "outputId": "97b0bfaa-e1eb-4041-e373-e93898d1597a"
   },
   "outputs": [],
   "source": [
    "# submission={\n",
    "#     'id':data['id'],\n",
    "#     'target':test_pred,\n",
    "#     'score':dtc_probs,\n",
    "# }\n",
    "\n",
    "# submission=pd.DataFrame(submission)\n",
    "# submission.to_csv(\"subt.csv\")\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "lr_auc = roc_auc_score(y_test, dtc_probs)\n",
    "# summarize scores\n",
    "print('Classifier: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, dtc_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, 'r',marker='.', label='SVM')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "kf = KFold(n_splits=4)\n",
    "mae_train = []\n",
    "mae_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGC4U9hKak6s"
   },
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "JTrGXE0XXqTj",
    "outputId": "8513b06f-6c20-4144-8d55-a09f6886c964"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_curve():\n",
    "    # instantiate\n",
    "    lg = SVC()\n",
    "\n",
    "    # fit\n",
    "    lg.fit(X_test, y_test)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "        \n",
    "    x1 = np.linspace(0, 10, 8, endpoint=True) produces\n",
    "        8 evenly spaced points in the range 0 to 10\n",
    "    \"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(lg, X_test, y_test, n_jobs=-1, cv=10, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"SVM\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n",
    "plot_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoPZmTEY1b0i"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pGNqRanarp_"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJfkcxJI1y-a"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "pred=classifier.predict(X_test)\n",
    "dtc_probs = classifier.predict_proba(X_test)\n",
    "dtc_probs=dtc_probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1m941-PkaumE"
   },
   "source": [
    "## Naive Bayes\n",
    "1. Test Train split Accuracy, precision, recall and f1 score\n",
    "2. F1 Score for 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfxLNhy_2Xnb",
    "outputId": "9cc77e04-8f90-4cf3-932d-3eca2ee67a0c"
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,pred)\n",
    "print(\"Complete Dataset Results\")\n",
    "print(\"confusion matrix\")\n",
    "print(cm)\n",
    "acc=accuracy_score(y_test, pred)\n",
    "pr=precision_score(y_test, pred,average='macro')\n",
    "re=recall_score(y_test, pred,average='macro')\n",
    "fs=f1_score(y_test, pred,average='macro')\n",
    "print('Accuracy score: {}'.format(acc))\n",
    "print('Precision score: {}'.format(pr))\n",
    "print('F1 score: {}'.format(fs))\n",
    "print('Recall score: {}'.format(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVaszpavaz10"
   },
   "source": [
    "## AUC ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "A_xLTwWE2aE9",
    "outputId": "674ea6ff-408a-4bdb-cb22-2c0f57e4a3c9"
   },
   "outputs": [],
   "source": [
    "# submission={\n",
    "#     'id':data['id'],\n",
    "#     'target':test_pred,\n",
    "#     'score':dtc_probs,\n",
    "# }\n",
    "\n",
    "# submission=pd.DataFrame(submission)\n",
    "# submission.to_csv(\"subt.csv\")\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "lr_auc = roc_auc_score(y_test, dtc_probs)\n",
    "# summarize scores\n",
    "print('Classifier: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, dtc_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, 'r',marker='.', label='Naive Bayes')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "kf = KFold(n_splits=4)\n",
    "mae_train = []\n",
    "mae_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4K_F_zWea5BC"
   },
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "8ZdlrRgZ2eiu",
    "outputId": "8f46cb3f-7c0f-4c27-b796-e85ac1038713"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_curve():\n",
    "    # instantiate\n",
    "    lg = GaussianNB()\n",
    "\n",
    "    # fit\n",
    "    lg.fit(X_test, y_test)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "        \n",
    "    x1 = np.linspace(0, 10, 8, endpoint=True) produces\n",
    "        8 evenly spaced points in the range 0 to 10\n",
    "    \"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(lg, X_test, y_test, n_jobs=-1, cv=10, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Naive Bayes\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n",
    "plot_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHr9h3_Ka_ET"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMhdegl06669"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "pred=classifier.predict(X_test)\n",
    "dtc_probs = classifier.predict_proba(X_test)\n",
    "dtc_probs=dtc_probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FQv9m1AbDCp"
   },
   "source": [
    "## Random Forest\n",
    "1. Test Train split Accuracy, precision, recall and f1 score\n",
    "2. F1 Score for 10 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAwgfrik6-pC",
    "outputId": "59bb725d-4d16-4dec-80d8-f9275552e8f0"
   },
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,pred)\n",
    "print(\"confusion matrix\")\n",
    "print(\"Complete Dataset Results\")\n",
    "print(cm)\n",
    "acc=accuracy_score(y_test, pred)\n",
    "pr=precision_score(y_test, pred,average='macro')\n",
    "re=recall_score(y_test, pred,average='macro')\n",
    "fs=f1_score(y_test, pred,average='macro')\n",
    "print('Accuracy score: {}'.format(acc))\n",
    "print('Precision score: {}'.format(pr))\n",
    "print('F1 score: {}'.format(fs))\n",
    "print('Recall score: {}'.format(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g2BlTo0bKqS"
   },
   "source": [
    "## AUC ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "TV2IrHNQ7OP-",
    "outputId": "36d57bbb-f1f6-43dc-ed62-2efbb059ca98"
   },
   "outputs": [],
   "source": [
    "# submission={\n",
    "#     'id':data['id'],\n",
    "#     'target':test_pred,\n",
    "#     'score':dtc_probs,\n",
    "# }\n",
    "\n",
    "# submission=pd.DataFrame(submission)\n",
    "# submission.to_csv(\"subt.csv\")\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "lr_auc = roc_auc_score(y_test, dtc_probs)\n",
    "# summarize scores\n",
    "print('Classifier: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, dtc_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(lr_fpr, lr_tpr, 'r',marker='.', label='Random Forest')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "kf = KFold(n_splits=4)\n",
    "mae_train = []\n",
    "mae_test = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OfmFlhHbOvk"
   },
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "EeHfKC7a7TCu",
    "outputId": "02c679f2-8ec2-451e-e12d-787dd3dfaf60"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_curve():\n",
    "    # instantiate\n",
    "    lg = RandomForestClassifier()\n",
    "\n",
    "    # fit\n",
    "    lg.fit(X_test, y_test)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "        \n",
    "    x1 = np.linspace(0, 10, 8, endpoint=True) produces\n",
    "        8 evenly spaced points in the range 0 to 10\n",
    "    \"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(lg, X_test, y_test, n_jobs=-1, cv=10, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Random Forest\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # box-like grid\n",
    "    plt.grid()\n",
    "    \n",
    "    # plot the std deviation as a transparent range at each training set size\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    \n",
    "    # plot the average training and test score lines at each training set size\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "    \n",
    "    # sizes the window for readability and displays the plot\n",
    "    # shows error from 0 to 1.1\n",
    "    plt.ylim(-.1,1.1)\n",
    "    plt.show()\n",
    "plot_curve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnYQa4k07VyP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "approach 2 test classification 70-100 tfidf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
